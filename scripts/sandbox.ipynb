{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlayer = model.layer1[1].conv1\n",
    "scale_factor = 2\n",
    "kernel_vectors = xlayer.weight.flatten(1)\n",
    "l2_distances = torch.cdist(kernel_vectors, kernel_vectors).triu().unsqueeze(0)\n",
    "l2_blocks = torch.nn.functional.unfold(l2_distances, kernel_size=scale_factor, stride=scale_factor, padding=0).T\n",
    "step_size = (l2_distances.shape[1] // (scale_factor )) + 1\n",
    "extract_indices = torch.arange(0, l2_blocks.shape[0], step=step_size)\n",
    "repulsion_loss = -l2_blocks[extract_indices].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8898, 1.9744, 1.9916, 1.9042, 2.0190, 2.0717, 2.0623, 2.1084, 2.0609,\n",
       "        1.9098, 2.0160, 1.9300, 2.0273, 2.0526, 2.0465, 2.0106, 1.9866, 2.0052,\n",
       "        1.9085, 2.0136, 2.0548, 1.9624, 1.9319, 1.9214, 2.0467, 1.9270, 2.0017,\n",
       "        1.9693, 2.0557, 1.9716, 1.9894, 1.9667], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_blocks[extract_indices].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-63.7877, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repulsion_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "tot_repulsion_loss = 0\n",
    "for name, param in model.named_modules():\n",
    "    if \"conv\" in name and \"layer\" in name:\n",
    "        kernel_vectors = param.weight.flatten(1)\n",
    "        l2_distances = torch.cdist(kernel_vectors, kernel_vectors).triu().unsqueeze(0)\n",
    "        l2_blocks = torch.nn.functional.unfold(l2_distances, kernel_size=scale_factor, stride=scale_factor, padding=0).T\n",
    "        step_size = (l2_distances.shape[1] // (scale_factor )) + 1\n",
    "        extract_indices = torch.arange(0, l2_blocks.shape[0], step=step_size)\n",
    "        repulsion_loss = -l2_blocks[extract_indices].sum()\n",
    "        tot_repulsion_loss+=repulsion_loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
